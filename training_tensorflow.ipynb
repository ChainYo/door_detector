{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"data/cropped\"\n",
    "\n",
    "train_paths = sorted(list(paths.list_images(f\"{dataset}/train\")))\n",
    "val_paths = sorted(list(paths.list_images(f\"{dataset}/val\")))\n",
    "test_paths = sorted(list(paths.list_images(f\"{dataset}/test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(paths: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Fonction permettant la création d'un jeu de données d'images à partir d'une liste\n",
    "    de chemins d'accès à ces images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    paths: \n",
    "        Chemin d'accès des données\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray:\n",
    "        Deux matrices contenant les images et leurs labels\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for path in paths:\n",
    "        label = path.split(os.path.sep)[-2]\n",
    "        image = load_img(path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # On encode les labels\n",
    "    mlb = LabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(train_paths)\n",
    "X_val, y_val = create_dataset(val_paths)\n",
    "X_test, y_test = create_dataset(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 224, 224, 3) (335, 3)\n",
      "(60, 224, 224, 3) (60, 3)\n",
      "(60, 224, 224, 3) (60, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([    \n",
    "    Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    BatchNormalization(axis=-1),\n",
    "    \n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    BatchNormalization(axis=-1),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(rate=0.3),\n",
    "    \n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 50\n",
    "\n",
    "opt = Adam(learning_rate=lr, decay=lr / (epochs * 0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ModelCheckpoint callback to record best weight only\n",
    "checkpointer = ModelCheckpoint(monitor='val_loss',\n",
    "                               filepath='saved_models_checkpoint/best_weights.h5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# add Earlystop callback\n",
    "earlystopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10,\n",
    "                              verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "# add ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,128,106,106] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/conv2d_7/Relu (defined at tmp/ipykernel_8978/961902480.py:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3921]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/chainyo/code/door_detector/training.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m clear_session\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=1'>2</a>\u001b[0m clear_session()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=3'>4</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=4'>5</a>\u001b[0m     \u001b[39m# aug.flow(X_train, y_train, batch_size=32),\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=5'>6</a>\u001b[0m     X_train, y_train, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=6'>7</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=7'>8</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=8'>9</a>\u001b[0m         checkpointer, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=9'>10</a>\u001b[0m         earlystopping, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=10'>11</a>\u001b[0m         reduce_lr\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=11'>12</a>\u001b[0m     ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=12'>13</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chainyo/code/door_detector/training.ipynb#ch0000008?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1176'>1177</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1177'>1178</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1178'>1179</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1179'>1180</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1180'>1181</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1181'>1182</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1182'>1183</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1183'>1184</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1184'>1185</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/keras/engine/training.py?line=1185'>1186</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=881'>882</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=883'>884</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=884'>885</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=886'>887</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=887'>888</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=915'>916</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=918'>919</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=919'>920</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=920'>921</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=3035'>3036</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=3036'>3037</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=3037'>3038</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=3038'>3039</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=3039'>3040</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1958'>1959</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1959'>1960</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1960'>1961</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1961'>1962</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1962'>1963</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1963'>1964</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1964'>1965</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1965'>1966</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1966'>1967</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1967'>1968</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1968'>1969</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=588'>589</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=589'>590</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=602'>603</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=603'>604</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/tf-training/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,128,106,106] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/conv2d_7/Relu (defined at tmp/ipykernel_8978/961902480.py:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3921]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()\n",
    "\n",
    "history = model.fit(\n",
    "    # aug.flow(X_train, y_train, batch_size=32),\n",
    "    X_train, y_train, \n",
    "    epochs=epochs, \n",
    "    callbacks=[\n",
    "        checkpointer, \n",
    "        earlystopping, \n",
    "        reduce_lr\n",
    "    ],\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "# Heatmap to see how images are classified\n",
    "import seaborn as sns\n",
    "\n",
    "conf = confusion_matrix(y_test.argmax(axis=1), pred.argmax(axis=1))\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(conf, cmap='mako', annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save last checkpoint\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "537a63c4869648ada7f30407d13a04f2db6c55637f4b3c28f46c671cf3e48dc8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('door_detector')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
